{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378c04ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during transcription: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from googletrans import Translator\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key securely (environment variable is preferred)\n",
    "openai.api_key = os.getenv(\"apikey\")  # Set API key as an environment variable\n",
    "\n",
    "# Path to your audio file\n",
    "audio_file_path = \"D:/Yogana/welcome.mp3\"\n",
    "\n",
    "# Function to transcribe audio using OpenAI Whisper\n",
    "def transcribe_audio(audio_file_path):\n",
    "    try:\n",
    "        with open(audio_file_path, \"rb\") as audio_file:\n",
    "            response = openai.Audio.transcribe(\n",
    "                file=audio_file,\n",
    "                model=\"whisper-1\"  # Whisper model for audio transcription\n",
    "            )\n",
    "            transcription_text = response['text']\n",
    "            return transcription_text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during transcription: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to translate text into multiple languages\n",
    "def translate_text(text):\n",
    "    translator = Translator()\n",
    "    translated_text_english = translator.translate(text, src='auto', dest='en').text\n",
    "    translated_text_malayalam = translator.translate(text, src='auto', dest='ml').text\n",
    "    translated_text_telugu = translator.translate(text, src='auto', dest='te').text\n",
    "    return translated_text_english, translated_text_malayalam, translated_text_telugu\n",
    "\n",
    "# Function to generate speech using a consistent voice (suggest using a custom TTS service for this)\n",
    "def generate_speech(text, language, output_file):\n",
    "    # Here you can use a service like Eleven Labs, Google Cloud TTS, or similar for consistent voice across languages\n",
    "    # For simplicity, we'll use gTTS here (note this won't give consistent voice tones across languages)\n",
    "    from gtts import gTTS\n",
    "    tts = gTTS(text, lang=language)\n",
    "    tts.save(output_file)\n",
    "    print(f\"Generated speech file saved as {output_file}\")\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Transcribe audio\n",
    "    transcription_text = transcribe_audio(audio_file_path)\n",
    "    \n",
    "    if transcription_text:\n",
    "        print(\"Transcription Result: \", transcription_text)\n",
    "        \n",
    "        # Step 2: Translate the transcription into multiple languages\n",
    "        translated_text_english, translated_text_malayalam, translated_text_telugu = translate_text(transcription_text)\n",
    "        \n",
    "        print(\"\\nTranslated Text (English):\", translated_text_english)\n",
    "        print(\"Translated Text (Malayalam):\", translated_text_malayalam)\n",
    "        print(\"Translated Text (Telugu):\", translated_text_telugu)\n",
    "        \n",
    "        # Step 3: Generate speech for each language using TTS service\n",
    "        generate_speech(translated_text_english, 'en', \"output_english.mp3\")\n",
    "        generate_speech(translated_text_malayalam, 'ml', \"output_malayalam.mp3\")\n",
    "        generate_speech(translated_text_telugu, 'te', \"output_telugu.mp3\")\n",
    "        \n",
    "        print(\"\\nGenerated speech files saved as 'output_english.mp3', 'output_malayalam.mp3', and 'output_telugu.mp3'.\")\n",
    "        \n",
    "        # Optionally, you can play the generated speech files on Windows\n",
    "        os.system(\"start output_english.mp3\")\n",
    "        os.system(\"start output_malayalam.mp3\")\n",
    "        os.system(\"start output_telugu.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3e4597",
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYOUR_OPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Google Cloud TTS Client setup\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m client \u001b[38;5;241m=\u001b[39m texttospeech\u001b[38;5;241m.\u001b[39mTextToSpeechClient()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Path to your audio file\u001b[39;00m\n\u001b[0;32m     13\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/Yogana/welcome.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\texttospeech_v1\\services\\text_to_speech\\client.py:635\u001b[0m, in \u001b[0;36mTextToSpeechClient.__init__\u001b[1;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[0;32m    627\u001b[0m transport_init: Union[\n\u001b[0;32m    628\u001b[0m     Type[TextToSpeechTransport], Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, TextToSpeechTransport]\n\u001b[0;32m    629\u001b[0m ] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, TextToSpeechTransport], transport)\n\u001b[0;32m    633\u001b[0m )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m transport_init(\n\u001b[0;32m    636\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    637\u001b[0m     credentials_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_options\u001b[38;5;241m.\u001b[39mcredentials_file,\n\u001b[0;32m    638\u001b[0m     host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_endpoint,\n\u001b[0;32m    639\u001b[0m     scopes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_options\u001b[38;5;241m.\u001b[39mscopes,\n\u001b[0;32m    640\u001b[0m     client_cert_source_for_mtls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_cert_source,\n\u001b[0;32m    641\u001b[0m     quota_project_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_options\u001b[38;5;241m.\u001b[39mquota_project_id,\n\u001b[0;32m    642\u001b[0m     client_info\u001b[38;5;241m=\u001b[39mclient_info,\n\u001b[0;32m    643\u001b[0m     always_use_jwt_access\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    644\u001b[0m     api_audience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_options\u001b[38;5;241m.\u001b[39mapi_audience,\n\u001b[0;32m    645\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\texttospeech_v1\\services\\text_to_speech\\transports\\grpc.py:153\u001b[0m, in \u001b[0;36mTextToSpeechGrpcTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[0;32m    149\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[0;32m    150\u001b[0m             )\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    154\u001b[0m     host\u001b[38;5;241m=\u001b[39mhost,\n\u001b[0;32m    155\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    156\u001b[0m     credentials_file\u001b[38;5;241m=\u001b[39mcredentials_file,\n\u001b[0;32m    157\u001b[0m     scopes\u001b[38;5;241m=\u001b[39mscopes,\n\u001b[0;32m    158\u001b[0m     quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id,\n\u001b[0;32m    159\u001b[0m     client_info\u001b[38;5;241m=\u001b[39mclient_info,\n\u001b[0;32m    160\u001b[0m     always_use_jwt_access\u001b[38;5;241m=\u001b[39malways_use_jwt_access,\n\u001b[0;32m    161\u001b[0m     api_audience\u001b[38;5;241m=\u001b[39mapi_audience,\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     channel_init \u001b[38;5;241m=\u001b[39m channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\texttospeech_v1\\services\\text_to_speech\\transports\\base.py:100\u001b[0m, in \u001b[0;36mTextToSpeechTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[0;32m     97\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_credentials:\n\u001b[1;32m--> 100\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mdefault(\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\auth\\_default.py:697\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    689\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    690\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    691\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    692\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    693\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[0;32m    694\u001b[0m             )\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 697\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from googletrans import Translator\n",
    "from google.cloud import texttospeech\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "# Google Cloud TTS Client setup\n",
    "client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Path to your audio file\n",
    "audio_file_path = \"D:/Yogana/welcome.mp3\"\n",
    "\n",
    "# Open the audio file and transcribe using Whisper model\n",
    "try:\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        # Upload the audio file and transcribe using Whisper model\n",
    "        response = openai.Audio.transcribe(\n",
    "            file=audio_file,\n",
    "            model=\"whisper-1\"  # Whisper model for audio transcription\n",
    "        )\n",
    "\n",
    "        # Get the transcription text\n",
    "        transcription_text = response['text']\n",
    "\n",
    "        # Print the transcription result\n",
    "        print(\"Transcription Result:\")\n",
    "        print(transcription_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during transcription: {e}\")\n",
    "    transcription_text = \"\"  # Proceed with empty transcription if an error occurred\n",
    "\n",
    "# Proceed if transcription was successful\n",
    "if transcription_text:\n",
    "    # Initialize the Translator\n",
    "    translator = Translator()\n",
    "\n",
    "    # Translate to different languages\n",
    "    translated_text_english = translator.translate(transcription_text, src='auto', dest='en').text\n",
    "    translated_text_malayalam = translator.translate(transcription_text, src='auto', dest='ml').text\n",
    "    translated_text_telugu = translator.translate(transcription_text, src='auto', dest='te').text\n",
    "\n",
    "    # Print translated text\n",
    "    print(\"\\nTranslated Text (English):\", translated_text_english)\n",
    "    print(\"Translated Text (Malayalam):\", translated_text_malayalam)\n",
    "    print(\"Translated Text (Telugu):\", translated_text_telugu)\n",
    "\n",
    "    # Set the voice and language for TTS\n",
    "    def synthesize_speech(text, language_code, filename):\n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "        voice = texttospeech.VoiceSelectionParams(\n",
    "            language_code=language_code,\n",
    "            ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL  # Choose the gender (NEUTRAL, MALE, FEMALE)\n",
    "        )\n",
    "        audio_config = texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "        )\n",
    "        response = client.synthesize_speech(\n",
    "            input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "        )\n",
    "\n",
    "        # Save the generated speech to a file\n",
    "        with open(filename, \"wb\") as out:\n",
    "            out.write(response.audio_content)\n",
    "        print(f\"Generated speech saved as {filename}\")\n",
    "\n",
    "    # Generate speech for each translated text\n",
    "    synthesize_speech(translated_text_english, 'en-US', \"output_english.mp3\")\n",
    "    synthesize_speech(translated_text_malayalam, 'ml-IN', \"output_malayalam.mp3\")\n",
    "    synthesize_speech(translated_text_telugu, 'te-IN', \"output_telugu.mp3\")\n",
    "\n",
    "    # Optionally, play the generated speech files\n",
    "    os.system(\"start output_english.mp3\")  # For Windows\n",
    "    os.system(\"start output_malayalam.mp3\")  # For Windows\n",
    "    os.system(\"start output_telugu.mp3\")  # For Windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4b96f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
